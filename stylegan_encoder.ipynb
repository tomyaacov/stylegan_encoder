{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stylegan-encoder",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMf94CZbDE/eODy3xsLqO3Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yosef-mashiach/stylegan_encoder/blob/main/stylegan_encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkxdgpXhQKhp",
        "outputId": "96133d33-d802-4fbc-ab17-869312f6ab36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "/content\n",
            "Cloning into 'stylegan_encoder'...\n",
            "remote: Enumerating objects: 197, done.\u001b[K\n",
            "remote: Total 197 (delta 0), reused 0 (delta 0), pack-reused 197\u001b[K\n",
            "Receiving objects: 100% (197/197), 51.72 MiB | 35.14 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n",
            "/content/stylegan_encoder\n",
            "[Errno 2] No such file or directory: 'stylegan_encoder'\n",
            "/content/stylegan_encoder\n",
            "/content/stylegan_encoder/cache\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19B138TWKeOs-JIol0_K-CCCDMYXbK5bk\n",
            "To: /content/stylegan_encoder/cache/263e666dc20e26dcbfa514733c1d1f81_karras2019stylegan-ffhq-1024x1024.pkl\n",
            "100% 325M/325M [00:03<00:00, 83.1MB/s]\n",
            "/content/stylegan_encoder\n",
            "WARNING:tensorflow:From /content/stylegan_encoder/dnnlib/tflib/tfutil.py:34: The name tf.Dimension is deprecated. Please use tf.compat.v1.Dimension instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan_encoder/dnnlib/tflib/tfutil.py:74: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan_encoder/dnnlib/tflib/tfutil.py:128: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Using TensorFlow backend.\n",
            "1.15.2\n",
            "WARNING:tensorflow:From /content/stylegan_encoder/dnnlib/tflib/tfutil.py:97: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan_encoder/dnnlib/tflib/tfutil.py:109: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan_encoder/dnnlib/tflib/tfutil.py:132: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan_encoder/dnnlib/tflib/network.py:142: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan_encoder/dnnlib/tflib/network.py:150: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan_encoder/dnnlib/tflib/tfutil.py:76: The name tf.VariableScope is deprecated. Please use tf.compat.v1.VariableScope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan_encoder/dnnlib/tflib/network.py:151: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan_encoder/dnnlib/tflib/network.py:154: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan_encoder/dnnlib/tflib/network.py:182: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan_encoder/dnnlib/tflib/tfutil.py:200: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From <string>:364: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/stylegan_encoder/encoder/generator_model.py:86: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "Downloading https://drive.google.com/uc?id=1N2-m9qszOeVC9Tq77WxsLnuWwOedQiD2 ... done\n",
            "WARNING:tensorflow:From /content/stylegan_encoder/encoder/perceptual_model.py:101: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan_encoder/encoder/perceptual_model.py:103: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan_encoder/encoder/perceptual_model.py:108: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "  0% 0/38 [00:00<?, ?it/s]WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "\n",
            "  0% 0/100 [00:00<?, ?it/s]\u001b[AWARNING:tensorflow:From /content/stylegan_encoder/encoder/perceptual_model.py:239: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:281: setdiff1d (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "This op will be removed after the deprecation date. Please switch to tf.sets.difference().\n",
            "\n",
            "070391: loss 380.9553; lr 0.0200:   0% 0/100 [00:06<?, ?it/s]\u001b[A\n",
            "070391: loss 380.9553; lr 0.0200:   1% 1/100 [00:07<12:16,  7.44s/it]\u001b[A\n",
            "070391: loss 327.6472; lr 0.0200:   1% 1/100 [00:07<12:16,  7.44s/it]\u001b[A\n",
            "070391: loss 327.6472; lr 0.0200:   2% 2/100 [00:07<05:20,  3.27s/it]\u001b[A\n",
            "070391: loss 290.2242; lr 0.0200:   2% 2/100 [00:08<05:20,  3.27s/it]\u001b[A\n",
            "070391: loss 290.2242; lr 0.0200:   3% 3/100 [00:08<03:07,  1.93s/it]\u001b[A\n",
            "070391: loss 265.9875; lr 0.0200:   3% 3/100 [00:08<03:07,  1.93s/it]\u001b[A\n",
            "070391: loss 265.9875; lr 0.0200:   4% 4/100 [00:08<02:05,  1.31s/it]\u001b[A\n",
            "070391: loss 246.0155; lr 0.0200:   4% 4/100 [00:08<02:05,  1.31s/it]\u001b[A\n",
            "070391: loss 246.0155; lr 0.0200:   5% 5/100 [00:08<01:31,  1.04it/s]\u001b[A\n",
            "070391: loss 239.9031; lr 0.0200:   5% 5/100 [00:09<01:31,  1.04it/s]\u001b[A\n",
            "070391: loss 239.9031; lr 0.0200:   6% 6/100 [00:09<01:10,  1.33it/s]\u001b[A\n",
            "070391: loss 221.9922; lr 0.0200:   6% 6/100 [00:09<01:10,  1.33it/s]\u001b[A\n",
            "070391: loss 221.9922; lr 0.0200:   7% 7/100 [00:09<00:57,  1.62it/s]\u001b[A\n",
            "070391: loss 210.1698; lr 0.0200:   7% 7/100 [00:09<00:57,  1.62it/s]\u001b[A\n",
            "070391: loss 210.1698; lr 0.0200:   8% 8/100 [00:09<00:48,  1.88it/s]\u001b[A\n",
            "070391: loss 205.7742; lr 0.0200:   8% 8/100 [00:10<00:48,  1.88it/s]\u001b[A\n",
            "070391: loss 205.7742; lr 0.0200:   9% 9/100 [00:10<00:43,  2.11it/s]\u001b[A\n",
            "070391: loss 199.7553; lr 0.0180:   9% 9/100 [00:10<00:43,  2.11it/s]\u001b[A\n",
            "070391: loss 199.7553; lr 0.0180:  10% 10/100 [00:10<00:39,  2.30it/s]\u001b[A\n",
            "070391: loss 191.6009; lr 0.0180:  10% 10/100 [00:10<00:39,  2.30it/s]\u001b[A\n",
            "070391: loss 191.6009; lr 0.0180:  11% 11/100 [00:10<00:36,  2.45it/s]\u001b[A\n",
            "070391: loss 183.4998; lr 0.0180:  11% 11/100 [00:11<00:36,  2.45it/s]\u001b[A\n",
            "070391: loss 183.4998; lr 0.0180:  12% 12/100 [00:11<00:34,  2.57it/s]\u001b[A\n",
            "070391: loss 179.4379; lr 0.0180:  12% 12/100 [00:11<00:34,  2.57it/s]\u001b[A\n",
            "070391: loss 179.4379; lr 0.0180:  13% 13/100 [00:11<00:32,  2.66it/s]\u001b[A\n",
            "070391: loss 174.1458; lr 0.0180:  13% 13/100 [00:11<00:32,  2.66it/s]\u001b[A\n",
            "070391: loss 174.1458; lr 0.0180:  14% 14/100 [00:11<00:31,  2.71it/s]\u001b[A\n",
            "070391: loss 170.2330; lr 0.0180:  14% 14/100 [00:12<00:31,  2.71it/s]\u001b[A\n",
            "070391: loss 170.2330; lr 0.0180:  15% 15/100 [00:12<00:30,  2.76it/s]\u001b[A\n",
            "070391: loss 165.9885; lr 0.0180:  15% 15/100 [00:12<00:30,  2.76it/s]\u001b[A\n",
            "070391: loss 165.9885; lr 0.0180:  16% 16/100 [00:12<00:30,  2.79it/s]\u001b[A\n",
            "070391: loss 162.7931; lr 0.0180:  16% 16/100 [00:12<00:30,  2.79it/s]\u001b[A\n",
            "070391: loss 162.7931; lr 0.0180:  17% 17/100 [00:12<00:29,  2.82it/s]\u001b[A\n",
            "070391: loss 159.9008; lr 0.0180:  17% 17/100 [00:13<00:29,  2.82it/s]\u001b[A\n",
            "070391: loss 159.9008; lr 0.0180:  18% 18/100 [00:13<00:28,  2.83it/s]\u001b[A\n",
            "070391: loss 156.0388; lr 0.0180:  18% 18/100 [00:13<00:28,  2.83it/s]\u001b[A\n",
            "070391: loss 156.0388; lr 0.0180:  19% 19/100 [00:13<00:28,  2.85it/s]\u001b[A\n",
            "070391: loss 151.0464; lr 0.0162:  19% 19/100 [00:13<00:28,  2.85it/s]\u001b[A\n",
            "070391: loss 151.0464; lr 0.0162:  20% 20/100 [00:14<00:28,  2.84it/s]\u001b[A\n",
            "070391: loss 147.6557; lr 0.0162:  20% 20/100 [00:14<00:28,  2.84it/s]\u001b[A\n",
            "070391: loss 147.6557; lr 0.0162:  21% 21/100 [00:14<00:27,  2.84it/s]\u001b[A\n",
            "070391: loss 146.8879; lr 0.0162:  21% 21/100 [00:14<00:27,  2.84it/s]\u001b[A\n",
            "070391: loss 146.8879; lr 0.0162:  22% 22/100 [00:14<00:27,  2.85it/s]\u001b[A\n",
            "070391: loss 145.6289; lr 0.0162:  22% 22/100 [00:15<00:27,  2.85it/s]\u001b[A\n",
            "070391: loss 145.6289; lr 0.0162:  23% 23/100 [00:15<00:26,  2.86it/s]\u001b[A\n",
            "070391: loss 142.9350; lr 0.0162:  23% 23/100 [00:15<00:26,  2.86it/s]\u001b[A\n",
            "070391: loss 142.9350; lr 0.0162:  24% 24/100 [00:15<00:26,  2.87it/s]\u001b[A\n",
            "070391: loss 140.4373; lr 0.0162:  24% 24/100 [00:15<00:26,  2.87it/s]\u001b[A\n",
            "070391: loss 140.4373; lr 0.0162:  25% 25/100 [00:15<00:26,  2.87it/s]\u001b[A\n",
            "070391: loss 138.6430; lr 0.0162:  25% 25/100 [00:16<00:26,  2.87it/s]\u001b[A\n",
            "070391: loss 138.6430; lr 0.0162:  26% 26/100 [00:16<00:25,  2.87it/s]\u001b[A\n",
            "070391: loss 136.7948; lr 0.0162:  26% 26/100 [00:16<00:25,  2.87it/s]\u001b[A\n",
            "070391: loss 136.7948; lr 0.0162:  27% 27/100 [00:16<00:25,  2.87it/s]\u001b[A\n",
            "070391: loss 133.5245; lr 0.0162:  27% 27/100 [00:16<00:25,  2.87it/s]\u001b[A\n",
            "070391: loss 133.5245; lr 0.0162:  28% 28/100 [00:16<00:25,  2.88it/s]\u001b[A\n",
            "070391: loss 131.6947; lr 0.0162:  28% 28/100 [00:17<00:25,  2.88it/s]\u001b[A\n",
            "070391: loss 131.6947; lr 0.0162:  29% 29/100 [00:17<00:24,  2.87it/s]\u001b[A\n",
            "070391: loss 131.3903; lr 0.0146:  29% 29/100 [00:17<00:24,  2.87it/s]\u001b[A\n",
            "070391: loss 131.3903; lr 0.0146:  30% 30/100 [00:17<00:24,  2.88it/s]\u001b[A\n",
            "070391: loss 130.4514; lr 0.0146:  30% 30/100 [00:17<00:24,  2.88it/s]\u001b[A\n",
            "070391: loss 130.4514; lr 0.0146:  31% 31/100 [00:17<00:23,  2.88it/s]\u001b[A\n",
            "070391: loss 128.6343; lr 0.0146:  31% 31/100 [00:18<00:23,  2.88it/s]\u001b[A\n",
            "070391: loss 128.6343; lr 0.0146:  32% 32/100 [00:18<00:23,  2.88it/s]\u001b[A\n",
            "070391: loss 127.2073; lr 0.0146:  32% 32/100 [00:18<00:23,  2.88it/s]\u001b[A\n",
            "070391: loss 127.2073; lr 0.0146:  33% 33/100 [00:18<00:23,  2.89it/s]\u001b[A\n",
            "070391: loss 125.8714; lr 0.0146:  33% 33/100 [00:18<00:23,  2.89it/s]\u001b[A\n",
            "070391: loss 125.8714; lr 0.0146:  34% 34/100 [00:18<00:22,  2.89it/s]\u001b[A\n",
            "070391: loss 124.2379; lr 0.0146:  34% 34/100 [00:19<00:22,  2.89it/s]\u001b[A\n",
            "070391: loss 124.2379; lr 0.0146:  35% 35/100 [00:19<00:22,  2.89it/s]\u001b[A\n",
            "070391: loss 122.8569; lr 0.0146:  35% 35/100 [00:19<00:22,  2.89it/s]\u001b[A\n",
            "070391: loss 122.8569; lr 0.0146:  36% 36/100 [00:19<00:22,  2.88it/s]\u001b[A\n",
            "070391: loss 121.8348; lr 0.0146:  36% 36/100 [00:19<00:22,  2.88it/s]\u001b[A\n",
            "070391: loss 121.8348; lr 0.0146:  37% 37/100 [00:19<00:21,  2.87it/s]\u001b[A\n",
            "070391: loss 121.1855; lr 0.0146:  37% 37/100 [00:20<00:21,  2.87it/s]\u001b[A\n",
            "070391: loss 121.1855; lr 0.0146:  38% 38/100 [00:20<00:21,  2.87it/s]\u001b[A\n",
            "070391: loss 120.5500; lr 0.0146:  38% 38/100 [00:20<00:21,  2.87it/s]\u001b[A\n",
            "070391: loss 120.5500; lr 0.0146:  39% 39/100 [00:20<00:21,  2.87it/s]\u001b[A\n",
            "070391: loss 118.5543; lr 0.0131:  39% 39/100 [00:20<00:21,  2.87it/s]\u001b[A\n",
            "070391: loss 118.5543; lr 0.0131:  40% 40/100 [00:20<00:20,  2.87it/s]\u001b[A\n",
            "070391: loss 117.9840; lr 0.0131:  40% 40/100 [00:21<00:20,  2.87it/s]\u001b[A\n",
            "070391: loss 117.9840; lr 0.0131:  41% 41/100 [00:21<00:20,  2.87it/s]\u001b[A\n",
            "070391: loss 116.9002; lr 0.0131:  41% 41/100 [00:21<00:20,  2.87it/s]\u001b[A\n",
            "070391: loss 116.9002; lr 0.0131:  42% 42/100 [00:21<00:20,  2.86it/s]\u001b[A\n",
            "070391: loss 116.0011; lr 0.0131:  42% 42/100 [00:21<00:20,  2.86it/s]\u001b[A\n",
            "070391: loss 116.0011; lr 0.0131:  43% 43/100 [00:22<00:19,  2.87it/s]\u001b[A\n",
            "070391: loss 114.9012; lr 0.0131:  43% 43/100 [00:22<00:19,  2.87it/s]\u001b[A\n",
            "070391: loss 114.9012; lr 0.0131:  44% 44/100 [00:22<00:19,  2.85it/s]\u001b[A\n",
            "070391: loss 113.9067; lr 0.0131:  44% 44/100 [00:22<00:19,  2.85it/s]\u001b[A\n",
            "070391: loss 113.9067; lr 0.0131:  45% 45/100 [00:22<00:19,  2.85it/s]\u001b[A\n",
            "070391: loss 114.0225; lr 0.0131:  45% 45/100 [00:23<00:19,  2.85it/s]\u001b[A\n",
            "070391: loss 114.0225; lr 0.0131:  46% 46/100 [00:23<00:18,  2.87it/s]\u001b[A\n",
            "070391: loss 112.1940; lr 0.0131:  46% 46/100 [00:23<00:18,  2.87it/s]\u001b[A\n",
            "070391: loss 112.1940; lr 0.0131:  47% 47/100 [00:23<00:18,  2.87it/s]\u001b[A\n",
            "070391: loss 112.2763; lr 0.0131:  47% 47/100 [00:23<00:18,  2.87it/s]\u001b[A\n",
            "070391: loss 112.2763; lr 0.0131:  48% 48/100 [00:23<00:18,  2.87it/s]\u001b[A\n",
            "070391: loss 113.2785; lr 0.0131:  48% 48/100 [00:24<00:18,  2.87it/s]\u001b[A\n",
            "070391: loss 113.2785; lr 0.0131:  49% 49/100 [00:24<00:17,  2.87it/s]\u001b[A\n",
            "070391: loss 114.6025; lr 0.0118:  49% 49/100 [00:24<00:17,  2.87it/s]\u001b[A\n",
            "070391: loss 114.6025; lr 0.0118:  50% 50/100 [00:24<00:17,  2.86it/s]\u001b[A\n",
            "070391: loss 114.3593; lr 0.0118:  50% 50/100 [00:24<00:17,  2.86it/s]\u001b[A\n",
            "070391: loss 114.3593; lr 0.0118:  51% 51/100 [00:24<00:17,  2.87it/s]\u001b[A\n",
            "070391: loss 116.2989; lr 0.0118:  51% 51/100 [00:25<00:17,  2.87it/s]\u001b[A\n",
            "070391: loss 116.2989; lr 0.0118:  52% 52/100 [00:25<00:16,  2.86it/s]\u001b[A\n",
            "070391: loss 114.3833; lr 0.0118:  52% 52/100 [00:25<00:16,  2.86it/s]\u001b[A\n",
            "070391: loss 114.3833; lr 0.0118:  53% 53/100 [00:25<00:16,  2.85it/s]\u001b[A\n",
            "070391: loss 115.2699; lr 0.0118:  53% 53/100 [00:25<00:16,  2.85it/s]\u001b[A\n",
            "070391: loss 115.2699; lr 0.0118:  54% 54/100 [00:25<00:16,  2.86it/s]\u001b[A\n",
            "070391: loss 113.3484; lr 0.0118:  54% 54/100 [00:26<00:16,  2.86it/s]\u001b[A\n",
            "070391: loss 113.3484; lr 0.0118:  55% 55/100 [00:26<00:15,  2.86it/s]\u001b[A\n",
            "070391: loss 113.5318; lr 0.0118:  55% 55/100 [00:26<00:15,  2.86it/s]\u001b[A\n",
            "070391: loss 113.5318; lr 0.0118:  56% 56/100 [00:26<00:15,  2.86it/s]\u001b[A\n",
            "070391: loss 112.1454; lr 0.0118:  56% 56/100 [00:26<00:15,  2.86it/s]\u001b[A\n",
            "070391: loss 112.1454; lr 0.0118:  57% 57/100 [00:26<00:15,  2.85it/s]\u001b[A\n",
            "070391: loss 111.7867; lr 0.0118:  57% 57/100 [00:27<00:15,  2.85it/s]\u001b[A\n",
            "070391: loss 111.7867; lr 0.0118:  58% 58/100 [00:27<00:14,  2.86it/s]\u001b[A\n",
            "070391: loss 110.1358; lr 0.0118:  58% 58/100 [00:27<00:14,  2.86it/s]\u001b[A\n",
            "070391: loss 110.1358; lr 0.0118:  59% 59/100 [00:27<00:14,  2.86it/s]\u001b[A\n",
            "070391: loss 110.1913; lr 0.0106:  59% 59/100 [00:27<00:14,  2.86it/s]\u001b[A\n",
            "070391: loss 110.1913; lr 0.0106:  60% 60/100 [00:27<00:13,  2.87it/s]\u001b[A\n",
            "070391: loss 109.1067; lr 0.0106:  60% 60/100 [00:28<00:13,  2.87it/s]\u001b[A\n",
            "070391: loss 109.1067; lr 0.0106:  61% 61/100 [00:28<00:13,  2.87it/s]\u001b[A\n",
            "070391: loss 108.6702; lr 0.0106:  61% 61/100 [00:28<00:13,  2.87it/s]\u001b[A\n",
            "070391: loss 108.6702; lr 0.0106:  62% 62/100 [00:28<00:13,  2.86it/s]\u001b[A\n",
            "070391: loss 107.5321; lr 0.0106:  62% 62/100 [00:28<00:13,  2.86it/s]\u001b[A\n",
            "070391: loss 107.5321; lr 0.0106:  63% 63/100 [00:29<00:12,  2.85it/s]\u001b[A\n",
            "070391: loss 107.0978; lr 0.0106:  63% 63/100 [00:29<00:12,  2.85it/s]\u001b[A\n",
            "070391: loss 107.0978; lr 0.0106:  64% 64/100 [00:29<00:12,  2.86it/s]\u001b[A\n",
            "070391: loss 106.5079; lr 0.0106:  64% 64/100 [00:29<00:12,  2.86it/s]\u001b[A\n",
            "070391: loss 106.5079; lr 0.0106:  65% 65/100 [00:29<00:12,  2.85it/s]\u001b[A\n",
            "070391: loss 106.2520; lr 0.0106:  65% 65/100 [00:30<00:12,  2.85it/s]\u001b[A\n",
            "070391: loss 106.2520; lr 0.0106:  66% 66/100 [00:30<00:11,  2.85it/s]\u001b[A\n",
            "070391: loss 105.5219; lr 0.0106:  66% 66/100 [00:30<00:11,  2.85it/s]\u001b[A\n",
            "070391: loss 105.5219; lr 0.0106:  67% 67/100 [00:30<00:11,  2.85it/s]\u001b[A\n",
            "070391: loss 105.0666; lr 0.0106:  67% 67/100 [00:30<00:11,  2.85it/s]\u001b[A\n",
            "070391: loss 105.0666; lr 0.0106:  68% 68/100 [00:30<00:11,  2.86it/s]\u001b[A\n",
            "070391: loss 104.4892; lr 0.0106:  68% 68/100 [00:31<00:11,  2.86it/s]\u001b[A\n",
            "070391: loss 104.4892; lr 0.0106:  69% 69/100 [00:31<00:10,  2.86it/s]\u001b[A\n",
            "070391: loss 103.9043; lr 0.0096:  69% 69/100 [00:31<00:10,  2.86it/s]\u001b[A\n",
            "070391: loss 103.9043; lr 0.0096:  70% 70/100 [00:31<00:10,  2.84it/s]\u001b[A\n",
            "070391: loss 103.6405; lr 0.0096:  70% 70/100 [00:31<00:10,  2.84it/s]\u001b[A\n",
            "070391: loss 103.6405; lr 0.0096:  71% 71/100 [00:31<00:10,  2.85it/s]\u001b[A\n",
            "070391: loss 103.0511; lr 0.0096:  71% 71/100 [00:32<00:10,  2.85it/s]\u001b[A\n",
            "070391: loss 103.0511; lr 0.0096:  72% 72/100 [00:32<00:09,  2.84it/s]\u001b[A\n",
            "070391: loss 102.5679; lr 0.0096:  72% 72/100 [00:32<00:09,  2.84it/s]\u001b[A\n",
            "070391: loss 102.5679; lr 0.0096:  73% 73/100 [00:32<00:09,  2.84it/s]\u001b[A\n",
            "070391: loss 102.2682; lr 0.0096:  73% 73/100 [00:32<00:09,  2.84it/s]\u001b[A\n",
            "070391: loss 102.2682; lr 0.0096:  74% 74/100 [00:32<00:09,  2.85it/s]\u001b[A\n",
            "070391: loss 101.6387; lr 0.0096:  74% 74/100 [00:33<00:09,  2.85it/s]\u001b[A\n",
            "070391: loss 101.6387; lr 0.0096:  75% 75/100 [00:33<00:08,  2.84it/s]\u001b[A\n",
            "070391: loss 101.3201; lr 0.0096:  75% 75/100 [00:33<00:08,  2.84it/s]\u001b[A\n",
            "070391: loss 101.3201; lr 0.0096:  76% 76/100 [00:33<00:08,  2.84it/s]\u001b[A\n",
            "070391: loss 100.9221; lr 0.0096:  76% 76/100 [00:33<00:08,  2.84it/s]\u001b[A\n",
            "070391: loss 100.9221; lr 0.0096:  77% 77/100 [00:33<00:08,  2.85it/s]\u001b[A\n",
            "070391: loss 100.5569; lr 0.0096:  77% 77/100 [00:34<00:08,  2.85it/s]\u001b[A\n",
            "070391: loss 100.5569; lr 0.0096:  78% 78/100 [00:34<00:07,  2.85it/s]\u001b[A\n",
            "070391: loss 100.3396; lr 0.0096:  78% 78/100 [00:34<00:07,  2.85it/s]\u001b[A\n",
            "070391: loss 100.3396; lr 0.0096:  79% 79/100 [00:34<00:07,  2.83it/s]\u001b[A\n",
            "070391: loss 99.9781; lr 0.0086:  79% 79/100 [00:34<00:07,  2.83it/s] \u001b[A\n",
            "070391: loss 99.9781; lr 0.0086:  80% 80/100 [00:35<00:07,  2.83it/s]\u001b[A\n",
            "070391: loss 99.6969; lr 0.0086:  80% 80/100 [00:35<00:07,  2.83it/s]\u001b[A\n",
            "070391: loss 99.6969; lr 0.0086:  81% 81/100 [00:35<00:06,  2.82it/s]\u001b[A\n",
            "070391: loss 99.5192; lr 0.0086:  81% 81/100 [00:35<00:06,  2.82it/s]\u001b[A\n",
            "070391: loss 99.5192; lr 0.0086:  82% 82/100 [00:35<00:06,  2.83it/s]\u001b[A\n",
            "070391: loss 99.2649; lr 0.0086:  82% 82/100 [00:35<00:06,  2.83it/s]\u001b[A\n",
            "070391: loss 99.2649; lr 0.0086:  83% 83/100 [00:36<00:06,  2.83it/s]\u001b[A\n",
            "070391: loss 99.0299; lr 0.0086:  83% 83/100 [00:36<00:06,  2.83it/s]\u001b[A\n",
            "070391: loss 99.0299; lr 0.0086:  84% 84/100 [00:36<00:05,  2.83it/s]\u001b[A\n",
            "070391: loss 98.7430; lr 0.0086:  84% 84/100 [00:36<00:05,  2.83it/s]\u001b[A\n",
            "070391: loss 98.7430; lr 0.0086:  85% 85/100 [00:36<00:05,  2.84it/s]\u001b[A\n",
            "070391: loss 98.4509; lr 0.0086:  85% 85/100 [00:37<00:05,  2.84it/s]\u001b[A\n",
            "070391: loss 98.4509; lr 0.0086:  86% 86/100 [00:37<00:04,  2.84it/s]\u001b[A\n",
            "070391: loss 98.3183; lr 0.0086:  86% 86/100 [00:37<00:04,  2.84it/s]\u001b[A\n",
            "070391: loss 98.3183; lr 0.0086:  87% 87/100 [00:37<00:04,  2.83it/s]\u001b[A\n",
            "070391: loss 98.1502; lr 0.0086:  87% 87/100 [00:37<00:04,  2.83it/s]\u001b[A\n",
            "070391: loss 98.1502; lr 0.0086:  88% 88/100 [00:37<00:04,  2.84it/s]\u001b[A\n",
            "070391: loss 97.8907; lr 0.0086:  88% 88/100 [00:38<00:04,  2.84it/s]\u001b[A\n",
            "070391: loss 97.8907; lr 0.0086:  89% 89/100 [00:38<00:03,  2.84it/s]\u001b[A\n",
            "070391: loss 97.6222; lr 0.0077:  89% 89/100 [00:38<00:03,  2.84it/s]\u001b[A\n",
            "070391: loss 97.6222; lr 0.0077:  90% 90/100 [00:38<00:03,  2.85it/s]\u001b[A\n",
            "070391: loss 97.4093; lr 0.0077:  90% 90/100 [00:38<00:03,  2.85it/s]\u001b[A\n",
            "070391: loss 97.4093; lr 0.0077:  91% 91/100 [00:38<00:03,  2.84it/s]\u001b[A\n",
            "070391: loss 97.2367; lr 0.0077:  91% 91/100 [00:39<00:03,  2.84it/s]\u001b[A\n",
            "070391: loss 97.2367; lr 0.0077:  92% 92/100 [00:39<00:02,  2.84it/s]\u001b[A\n",
            "070391: loss 97.0884; lr 0.0077:  92% 92/100 [00:39<00:02,  2.84it/s]\u001b[A\n",
            "070391: loss 97.0884; lr 0.0077:  93% 93/100 [00:39<00:02,  2.84it/s]\u001b[A\n",
            "070391: loss 96.9508; lr 0.0077:  93% 93/100 [00:39<00:02,  2.84it/s]\u001b[A\n",
            "070391: loss 96.9508; lr 0.0077:  94% 94/100 [00:39<00:02,  2.84it/s]\u001b[A\n",
            "070391: loss 96.8539; lr 0.0077:  94% 94/100 [00:40<00:02,  2.84it/s]\u001b[A\n",
            "070391: loss 96.8539; lr 0.0077:  95% 95/100 [00:40<00:01,  2.83it/s]\u001b[A\n",
            "070391: loss 96.7159; lr 0.0077:  95% 95/100 [00:40<00:01,  2.83it/s]\u001b[A\n",
            "070391: loss 96.7159; lr 0.0077:  96% 96/100 [00:40<00:01,  2.86it/s]\u001b[A\n",
            "070391: loss 96.5144; lr 0.0077:  96% 96/100 [00:40<00:01,  2.86it/s]\u001b[A\n",
            "070391: loss 96.5144; lr 0.0077:  97% 97/100 [00:40<00:01,  2.84it/s]\u001b[A\n",
            "070391: loss 96.3792; lr 0.0077:  97% 97/100 [00:41<00:01,  2.84it/s]\u001b[A\n",
            "070391: loss 96.3792; lr 0.0077:  98% 98/100 [00:41<00:00,  2.83it/s]\u001b[A\n",
            "070391: loss 96.1601; lr 0.0077:  98% 98/100 [00:41<00:00,  2.83it/s]\u001b[A\n",
            "070391: loss 96.1601; lr 0.0077:  99% 99/100 [00:41<00:00,  2.83it/s]\u001b[A\n",
            "070391: loss 96.0698; lr 0.0070:  99% 99/100 [00:41<00:00,  2.83it/s]\u001b[A\n",
            "070391: loss 96.0698; lr 0.0070: 100% 100/100 [00:42<00:00,  2.83it/s]\u001b[A\n",
            "                                                                      \u001b[A070391  Loss 96.0698\n",
            "  3% 1/38 [00:44<27:13, 44.15s/it]\n",
            "  0% 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "070074: loss 417.3829; lr 0.0200:   0% 0/100 [00:03<?, ?it/s]\u001b[A\n",
            "070074: loss 417.3829; lr 0.0200:   1% 1/100 [00:04<06:38,  4.03s/it]\u001b[A\n",
            "070074: loss 354.4604; lr 0.0200:   1% 1/100 [00:04<06:38,  4.03s/it]\u001b[A\n",
            "070074: loss 354.4604; lr 0.0200:   2% 2/100 [00:04<03:02,  1.87s/it]\u001b[A\n",
            "070074: loss 324.3007; lr 0.0200:   2% 2/100 [00:04<03:02,  1.87s/it]\u001b[A\n",
            "070074: loss 324.3007; lr 0.0200:   3% 3/100 [00:04<01:54,  1.18s/it]\u001b[A\n",
            "070074: loss 302.4178; lr 0.0200:   3% 3/100 [00:05<01:54,  1.18s/it]\u001b[A\n",
            "070074: loss 302.4178; lr 0.0200:   4% 4/100 [00:05<01:21,  1.18it/s]\u001b[A\n",
            "070074: loss 287.7870; lr 0.0200:   4% 4/100 [00:05<01:21,  1.18it/s]\u001b[A\n",
            "070074: loss 287.7870; lr 0.0200:   5% 5/100 [00:05<01:03,  1.49it/s]\u001b[A\n",
            "070074: loss 276.4555; lr 0.0200:   5% 5/100 [00:05<01:03,  1.49it/s]\u001b[A\n",
            "070074: loss 276.4555; lr 0.0200:   6% 6/100 [00:05<00:53,  1.77it/s]\u001b[A\n",
            "070074: loss 263.2693; lr 0.0200:   6% 6/100 [00:06<00:53,  1.77it/s]\u001b[A\n",
            "070074: loss 263.2693; lr 0.0200:   7% 7/100 [00:06<00:46,  2.02it/s]\u001b[A\n",
            "070074: loss 249.8550; lr 0.0200:   7% 7/100 [00:06<00:46,  2.02it/s]\u001b[A\n",
            "070074: loss 249.8550; lr 0.0200:   8% 8/100 [00:06<00:41,  2.22it/s]\u001b[A\n",
            "070074: loss 236.4578; lr 0.0200:   8% 8/100 [00:06<00:41,  2.22it/s]\u001b[A\n",
            "070074: loss 236.4578; lr 0.0200:   9% 9/100 [00:06<00:38,  2.38it/s]\u001b[A\n",
            "070074: loss 224.6332; lr 0.0180:   9% 9/100 [00:07<00:38,  2.38it/s]\u001b[A\n",
            "070074: loss 224.6332; lr 0.0180:  10% 10/100 [00:07<00:36,  2.50it/s]\u001b[A\n",
            "070074: loss 219.8026; lr 0.0180:  10% 10/100 [00:07<00:36,  2.50it/s]\u001b[A\n",
            "070074: loss 219.8026; lr 0.0180:  11% 11/100 [00:07<00:34,  2.58it/s]\u001b[A\n",
            "070074: loss 214.5689; lr 0.0180:  11% 11/100 [00:07<00:34,  2.58it/s]\u001b[A\n",
            "070074: loss 214.5689; lr 0.0180:  12% 12/100 [00:07<00:33,  2.65it/s]\u001b[A\n",
            "070074: loss 208.5140; lr 0.0180:  12% 12/100 [00:08<00:33,  2.65it/s]\u001b[A\n",
            "070074: loss 208.5140; lr 0.0180:  13% 13/100 [00:08<00:32,  2.69it/s]\u001b[A\n",
            "070074: loss 201.9310; lr 0.0180:  13% 13/100 [00:08<00:32,  2.69it/s]\u001b[A\n",
            "070074: loss 201.9310; lr 0.0180:  14% 14/100 [00:08<00:31,  2.72it/s]\u001b[A\n",
            "070074: loss 194.3360; lr 0.0180:  14% 14/100 [00:08<00:31,  2.72it/s]\u001b[A\n",
            "070074: loss 194.3360; lr 0.0180:  15% 15/100 [00:09<00:30,  2.75it/s]\u001b[A\n",
            "070074: loss 189.5992; lr 0.0180:  15% 15/100 [00:09<00:30,  2.75it/s]\u001b[A\n",
            "070074: loss 189.5992; lr 0.0180:  16% 16/100 [00:09<00:30,  2.76it/s]\u001b[A\n",
            "070074: loss 185.4841; lr 0.0180:  16% 16/100 [00:09<00:30,  2.76it/s]\u001b[A\n",
            "070074: loss 185.4841; lr 0.0180:  17% 17/100 [00:09<00:29,  2.78it/s]\u001b[A\n",
            "070074: loss 182.5583; lr 0.0180:  17% 17/100 [00:09<00:29,  2.78it/s]\u001b[A\n",
            "070074: loss 182.5583; lr 0.0180:  18% 18/100 [00:10<00:29,  2.78it/s]\u001b[A\n",
            "070074: loss 177.0867; lr 0.0180:  18% 18/100 [00:10<00:29,  2.78it/s]\u001b[A\n",
            "070074: loss 177.0867; lr 0.0180:  19% 19/100 [00:10<00:29,  2.77it/s]\u001b[A\n",
            "070074: loss 172.3551; lr 0.0162:  19% 19/100 [00:10<00:29,  2.77it/s]\u001b[A\n",
            "070074: loss 172.3551; lr 0.0162:  20% 20/100 [00:10<00:29,  2.75it/s]\u001b[A\n",
            "070074: loss 169.4974; lr 0.0162:  20% 20/100 [00:11<00:29,  2.75it/s]\u001b[A\n",
            "070074: loss 169.4974; lr 0.0162:  21% 21/100 [00:11<00:28,  2.73it/s]\u001b[A\n",
            "070074: loss 167.4163; lr 0.0162:  21% 21/100 [00:11<00:28,  2.73it/s]\u001b[A\n",
            "070074: loss 167.4163; lr 0.0162:  22% 22/100 [00:11<00:28,  2.69it/s]\u001b[A\n",
            "070074: loss 169.0694; lr 0.0162:  22% 22/100 [00:11<00:28,  2.69it/s]\u001b[A\n",
            "070074: loss 169.0694; lr 0.0162:  23% 23/100 [00:11<00:29,  2.64it/s]\u001b[A\n",
            "070074: loss 167.3996; lr 0.0162:  23% 23/100 [00:12<00:29,  2.64it/s]\u001b[A\n",
            "070074: loss 167.3996; lr 0.0162:  24% 24/100 [00:12<00:28,  2.64it/s]\u001b[A\n",
            "070074: loss 162.5705; lr 0.0162:  24% 24/100 [00:12<00:28,  2.64it/s]\u001b[A\n",
            "070074: loss 162.5705; lr 0.0162:  25% 25/100 [00:12<00:27,  2.68it/s]\u001b[A\n",
            "070074: loss 159.6920; lr 0.0162:  25% 25/100 [00:12<00:27,  2.68it/s]\u001b[A\n",
            "070074: loss 159.6920; lr 0.0162:  26% 26/100 [00:13<00:27,  2.71it/s]\u001b[A\n",
            "070074: loss 159.3284; lr 0.0162:  26% 26/100 [00:13<00:27,  2.71it/s]\u001b[A\n",
            "070074: loss 159.3284; lr 0.0162:  27% 27/100 [00:13<00:26,  2.74it/s]\u001b[A\n",
            "070074: loss 157.2168; lr 0.0162:  27% 27/100 [00:13<00:26,  2.74it/s]\u001b[A\n",
            "070074: loss 157.2168; lr 0.0162:  28% 28/100 [00:13<00:26,  2.76it/s]\u001b[A\n",
            "070074: loss 153.1883; lr 0.0162:  28% 28/100 [00:14<00:26,  2.76it/s]\u001b[A\n",
            "070074: loss 153.1883; lr 0.0162:  29% 29/100 [00:14<00:25,  2.77it/s]\u001b[A\n",
            "070074: loss 150.9196; lr 0.0146:  29% 29/100 [00:14<00:25,  2.77it/s]\u001b[A\n",
            "070074: loss 150.9196; lr 0.0146:  30% 30/100 [00:14<00:25,  2.78it/s]\u001b[A\n",
            "070074: loss 150.3822; lr 0.0146:  30% 30/100 [00:14<00:25,  2.78it/s]\u001b[A\n",
            "070074: loss 150.3822; lr 0.0146:  31% 31/100 [00:14<00:24,  2.78it/s]\u001b[A\n",
            "070074: loss 148.7838; lr 0.0146:  31% 31/100 [00:15<00:24,  2.78it/s]\u001b[A\n",
            "070074: loss 148.7838; lr 0.0146:  32% 32/100 [00:15<00:24,  2.79it/s]\u001b[A"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 1.x\n",
        "%cd /content\n",
        "!git clone https://github.com/yosef-mashiach/stylegan_encoder\n",
        "%cd stylegan_encoder\n",
        "!mkdir -p cache\n",
        "%cd cache\n",
        "!gdown https://drive.google.com/uc?id=19B138TWKeOs-JIol0_K-CCCDMYXbK5bk\n",
        "%cd ..\n",
        "!python encode_images.py"
      ]
    }
  ]
}